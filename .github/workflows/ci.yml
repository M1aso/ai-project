name: CI
on:
  push:
    branches: [ main, dev ]
    tags:
      - "release-*"
  pull_request:
    branches: [ main, dev ]

jobs:
  contracts_lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      - run: |
          npx @stoplight/spectral-cli lint "libs/contracts/*.yaml" --ruleset libs/contracts/.spectral.yaml -f stylish -D --fail-severity=error

  unit_tests:
    needs: contracts_lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - run: pip install -r requirements.txt
      - run: pytest -q

  build_and_push:
    needs: unit_tests
    if: github.event_name == 'push'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [auth, profile, content, notifications, chat, analytics, content-worker]
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4

      - name: Derive lowercase owner for GHCR
        run: echo "OWNER_LC=${GITHUB_REPOSITORY_OWNER,,}" >> "$GITHUB_ENV"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & push image
        uses: docker/build-push-action@v6
        with:
          context: ./services/${{ matrix.service }}
          push: true
          tags: |
            ghcr.io/${{ env.OWNER_LC }}/${{ matrix.service }}:${{ github.sha }}
            ghcr.io/${{ env.OWNER_LC }}/${{ matrix.service }}:${{ github.ref_name }}

  # Auto-deploy to dev environment when pushing to dev branch
  auto_deploy_dev:
    needs: build_and_push
    if: github.ref == 'refs/heads/dev' && github.event_name == 'push'
    runs-on: ubuntu-latest
    environment: dev
    permissions:
      contents: read
      packages: read
      id-token: write
    steps:
      - uses: actions/checkout@v4
      
      - name: Derive lowercase owner for GHCR
        run: echo "OWNER_LC=${GITHUB_REPOSITORY_OWNER,,}" >> "$GITHUB_ENV"

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4

      - name: Setup Helm
        uses: azure/setup-helm@v4

      - name: Configure kubeconfig from secret
        env:
          KUBE_CONFIG: ${{ secrets.KUBE_CONFIG }}
        run: |
          if [ -n "${KUBE_CONFIG:-}" ]; then
            mkdir -p "$HOME/.kube"
            echo "$KUBE_CONFIG" | base64 -d > "$HOME/.kube/config"
            echo "‚úì Wrote kubeconfig from secret"
          else
            echo "‚Ü∑ KUBE_CONFIG is empty; skipping. Add it as an Environment secret."
          fi

      - name: Create GHCR imagePullSecret
        env:
          NS: dev
          GHCR_USERNAME: ${{ secrets.GHCR_USERNAME }}
          GHCR_PASSWORD: ${{ secrets.GHCR_TOKEN }}
        run: |
          set -euo pipefail
          if [ -n "${GHCR_USERNAME:-}" ] && [ -n "${GHCR_PASSWORD:-}" ]; then
            kubectl create namespace "$NS" --dry-run=client -o yaml | kubectl apply -f -
            kubectl -n "$NS" delete secret ghcr --ignore-not-found
            kubectl -n "$NS" create secret docker-registry ghcr \
              --docker-server=ghcr.io \
              --docker-username="$GHCR_USERNAME" \
              --docker-password="$GHCR_PASSWORD"
            echo "‚úì Created imagePullSecret 'ghcr' in namespace $NS"
          else
            echo "‚Ü∑ GHCR_USERNAME/GHCR_TOKEN not provided; skipping imagePullSecret creation."
          fi

      - name: Deploy api-gateway
        env:
          ENV: dev
          NS: dev
        run: |
          set -euo pipefail
          VALUES_FILE="deploy/helm/api-gateway/values.${ENV}.yaml"
          if [ -f "$VALUES_FILE" ]; then EXTRA_VALUES=(-f "$VALUES_FILE"); else EXTRA_VALUES=(); fi
          helm upgrade --install api-gateway deploy/helm/api-gateway \
            --namespace "$NS" --create-namespace \
            "${EXTRA_VALUES[@]}"

      - name: Deploy services
        env:
          ENV: dev
          NS: dev
        run: |
          set -euo pipefail
          for svc in auth profile content notifications chat analytics content-worker; do
            VALUES_FILE="deploy/helm/$svc/values.${ENV}.yaml"
            if [ -f "$VALUES_FILE" ]; then EXTRA_VALUES=(-f "$VALUES_FILE"); else EXTRA_VALUES=(); fi
            helm upgrade --install "$svc" "deploy/helm/$svc" \
              --namespace "$NS" --create-namespace \
              --set "image.repository=ghcr.io/${{ env.OWNER_LC }}/$svc" \
              --set "image.tag=${{ github.sha }}" \
              "${EXTRA_VALUES[@]}"
          done
          
          # Deploy Swagger UI separately (uses public image)
          helm upgrade --install swagger-ui deploy/helm/swagger-ui \
            --namespace "$NS" --create-namespace \
            -f deploy/helm/swagger-ui/values.dev.yaml

      - name: Restart deployments to pick up ConfigMap changes
        env:
          NS: dev
        run: |
          set -euo pipefail
          echo "üîÑ Restarting deployments to ensure ConfigMap changes are applied..."
          
          # Restart all services that might have ConfigMap dependencies
          SERVICES_TO_RESTART=(api-gateway auth profile content notifications chat analytics content-worker swagger-ui)
          
          # Track successful and failed restarts
          RESTARTED_SERVICES=()
          FAILED_SERVICES=()
          
          # Restart each deployment
          for svc in "${SERVICES_TO_RESTART[@]}"; do
            echo "üîÑ Restarting deployment: $svc"
            if kubectl get deployment "$svc" -n "$NS" >/dev/null 2>&1; then
              if kubectl rollout restart "deployment/$svc" -n "$NS"; then
                echo "‚úì Successfully triggered restart for $svc"
                RESTARTED_SERVICES+=("$svc")
              else
                echo "‚ùå Failed to restart $svc"
                FAILED_SERVICES+=("$svc")
              fi
            else
              echo "‚ö†Ô∏è  Deployment $svc not found, skipping restart"
            fi
          done
          
          # Wait for all restarted deployments to complete
          echo "‚è≥ Waiting for all restarted deployments to be ready..."
          for svc in "${RESTARTED_SERVICES[@]}"; do
            echo "Waiting for $svc rollout to complete..."
            if kubectl rollout status "deployment/$svc" -n "$NS" --timeout=300s; then
              echo "‚úÖ $svc rollout completed successfully"
            else
              echo "‚ùå $svc rollout failed or timed out"
              FAILED_SERVICES+=("$svc")
            fi
          done
          
          # Report results
          echo "üìä Restart Summary:"
          echo "‚úÖ Successfully restarted: ${RESTARTED_SERVICES[*]:-none}"
          if [ ${#FAILED_SERVICES[@]} -gt 0 ]; then
            echo "‚ùå Failed services: ${FAILED_SERVICES[*]}"
            echo "::warning::Some services failed to restart properly"
          else
            echo "üéâ All deployments restarted successfully!"
          fi

